{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZmpA3zRa4co"
      },
      "source": [
        "#Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b_V8G5NPVKeW"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics, svm\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdarSH2Ha8uW"
      },
      "source": [
        "# Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucqrzEdxhNtC",
        "outputId": "30e6ef6f-9142-48df-f95b-76a31d96fceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wBhqec2a_pd"
      },
      "source": [
        "Navigating to destination folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcd5hS3f6fSH",
        "outputId": "be4b024a-739f-4c30-a4df-c374a9923f3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MinorProject/Datasets\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/MinorProject/Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRDIwdnzbl-R"
      },
      "source": [
        "# Main Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rBtfj1XiZDYW"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "  mnb, svm_ = 1, 1\n",
        "  oppWords = pd.read_csv('CSV/opposite.csv')\n",
        "  unwanted = pd.read_csv('CSV/unwanted.csv')\n",
        "  exclude = list(unwanted['prepositions'].unique() )+ list(unwanted['pronouns'].unique())\n",
        "  reveres = ['not', 'hardly', 'never']\n",
        "  mertircs = {\n",
        "      'MTX':['accuracy', \n",
        "             'balanced_accuracy', \n",
        "             'f1', \n",
        "             'precision',\n",
        "             ],\n",
        "      'MNB':[],\n",
        "      'SVM':[],\n",
        "  }\n",
        "\n",
        "  @staticmethod\n",
        "  def store_metrics(y_true, y_pred, what, save = False): # https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "    if what in ['MNB', \"SVM\", 'AVG']:\n",
        "      if what == \"AVG\":\n",
        "        what += \"_MNB_SVM_\" + str(Model.mnb) + \"_\" + str(Model.svm_) +\"_\"\n",
        "      Model.mertircs[what] = []\n",
        "      Model.mertircs[what].append(metrics.accuracy_score(y_true, y_pred))\n",
        "      Model.mertircs[what].append(metrics.balanced_accuracy_score(y_true, y_pred))\n",
        "      Model.mertircs[what].append(metrics.f1_score(y_true, y_pred, average='weighted'))\n",
        "      Model.mertircs[what].append(metrics.precision_score(y_true, y_pred, average='weighted'))\n",
        "    else:\n",
        "      print('Invalide command !')\n",
        "    if save:\n",
        "      pd.DataFrame(Model.mertircs).to_csv('SAscore5.csv', index=False)\n",
        "      print('SAscore5.csv written !' )\n",
        "    return sum(Model.mertircs[what])\n",
        "  \n",
        "  @staticmethod\n",
        "  def oppFilter(sentence, do):\n",
        "    if not do:\n",
        "      return sentence\n",
        "    new_sentence =''\n",
        "    for word in sentence.split(' '):\n",
        "      if len(word) > 1 and word[0] == \"!\":\n",
        "        if len(Model.oppWords[Model.oppWords['word'] == word[1:]]) > 0:\n",
        "          word = Model.oppWords[Model.oppWords['word'] == word[1:]]['opposite'].array[0]\n",
        "        elif len(Model.oppWords[Model.oppWords['opposite'] == word[1:]]) > 0:\n",
        "          word = Model.oppWords[Model.oppWords['opposite'] == word[1:]]['word'].array[0]\n",
        "        else:\n",
        "          word = word[1:]\n",
        "      new_sentence += (str(word) + \" \")\n",
        "    return new_sentence[:-1]\n",
        "\n",
        "  @staticmethod\n",
        "  def filter_sentence(sentence):\n",
        "    notFilter = False\n",
        "    sentence = sentence.lower()\n",
        "    new_sentence ='' \n",
        "    for word in sentence.split(' '):\n",
        "      nw = ''\n",
        "      for i in word:\n",
        "        if i.isalpha():\n",
        "          nw += i\n",
        "      word = nw\n",
        "      if word not in Model.exclude:\n",
        "        if word in Model.reveres:\n",
        "          new_sentence += '!'\n",
        "          notFilter = True\n",
        "        else:\n",
        "          new_sentence += (word + \" \")\n",
        "    return Model.oppFilter(new_sentence[:-1], notFilter)\n",
        "\n",
        "  @staticmethod\n",
        "  def filter_df(df, to_filter_column, new_column):\n",
        "    df[new_column] = df[to_filter_column]\n",
        "    i = -1\n",
        "    for sentence in df[to_filter_column]:\n",
        "      i += 1\n",
        "      df[new_column][i] = Model.filter_sentence(sentence)\n",
        "    return df\n",
        "  \n",
        "  @staticmethod\n",
        "  def predict(statement, details=False):\n",
        "    try:\n",
        "      if details:\n",
        "        print(f'Input: \"{statement}\"')\n",
        "      statement = Model.filter_sentence(statement)\n",
        "      if details:\n",
        "        print(f'Filtered Input: {statement}')\n",
        "      svm_prob = Model.SVM_model.predict_proba(Model.vec.transform([statement]))[0]\n",
        "      mnb_prob = Model.MNB_model.predict_proba(Model.vec.transform([statement]))[0]\n",
        "      l = len(statement.split(' '))\n",
        "      if l>3:\n",
        "        avg = avg = (svm_prob*Model.svm_ + mnb_prob*Model.mnb)/(Model.svm_+Model.mnb)\n",
        "      else:\n",
        "        avg = svm_prob\n",
        "      classes = Model.MNB_model.classes_\n",
        "      res = classes[list(avg).index(avg.max())].upper()\n",
        "      if details:\n",
        "        print(f'THE OVERALL SENTIMENT OF GIVEN STATEMENT IS \"{res}\".\\n\\nDetails:')\n",
        "        print(f'SENTIMENT : MNB, SVM, AVG')\n",
        "        for i in range(len(classes)):\n",
        "          print(f'{classes[i]} : {format(mnb_prob[i]*100,\".4f\")}%, {format(svm_prob[i]*100,\".4f\")}%, {format(avg[i]*100,\".4f\")}%')\n",
        "        print(\"----------------------------\\n\")\n",
        "    except AttributeError:\n",
        "      print('Model is not yet generated.')\n",
        "      return\n",
        "    except TypeError:\n",
        "      print('Model is not yet generated.')\n",
        "      return\n",
        "\n",
        "    return {\n",
        "        'MNB' : mnb_prob,\n",
        "        'SVM' : svm_prob,\n",
        "        'AVG' : avg,\n",
        "        'res' : res,\n",
        "        'prob': avg.max()\n",
        "    }\n",
        "\n",
        "  @staticmethod\n",
        "  def updateModelVec(MNB_model, SVM_model, vec, save = False):\n",
        "    Model.MNB_model = MNB_model\n",
        "    Model.SVM_model = SVM_model\n",
        "    Model.vec = vec\n",
        "    if save:\n",
        "      pickle.dump(Model, open('Class/Model.sav', 'wb'))\n",
        "\n",
        "  @staticmethod\n",
        "  def train_test_split_(xColumn, yColumn):\n",
        "    x = Model.statementsDF[xColumn]\n",
        "    y = Model.statementsDF[yColumn]\n",
        "    Model.x, Model.x_test, Model.y, Model.y_test = train_test_split(x,y, stratify=y, test_size=0.15, random_state=22)\n",
        "\n",
        "  @staticmethod\n",
        "  def vectorize():\n",
        "    Model.vec = CountVectorizer(stop_words='english')\n",
        "    Model.x_SVM = Model.vec.fit_transform(Model.x)\n",
        "    Model.x_test_SVM = Model.vec.transform(Model.x_test)\n",
        "    Model.x_MNB = Model.vec.fit_transform(Model.x).toarray()\n",
        "    Model.x_test_MNB = Model.vec.transform(Model.x_test).toarray()\n",
        "    pickle.dump(Model.vec, open('Model/vectorizer.sav', 'wb'))\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def generateModel(df, xColumn, yColumn): # x, y -> statements, sentiment\n",
        "      print('Filtering the DataFrame ...')\n",
        "      Model.statementsDF = Model.filter_df(df, xColumn, 'New' + xColumn)\n",
        "      print('Performing Train/Test split ...')\n",
        "      Model.train_test_split_('New' + xColumn, yColumn)\n",
        "      print('Vectorizing ...')\n",
        "      Model.vectorize()\n",
        "\n",
        "      print('Generating SVM Model...')\n",
        "      modelSVM = svm.SVC(kernel='linear', probability=True)\n",
        "      modelSVM.fit(Model.x_SVM, Model.y)\n",
        "      pickle.dump(modelSVM, open('Model/modelSVM.sav', 'wb'))\n",
        "      print('Generating MNB Model...')\n",
        "      modelMNB = MultinomialNB()\n",
        "      modelMNB.fit(Model.x_MNB, Model.y)\n",
        "      pickle.dump(modelMNB, open('Model/modelMNB.sav', 'wb'))\n",
        "\n",
        "      Model.updateModelVec(modelMNB, modelSVM, Model.vec)\n",
        "\n",
        "      print('Calculationg model scores ...')\n",
        "      Model.store_metrics(list(Model.y_test), list(Model.SVM_model.predict(Model.vec.transform(Model.x_test))), \"SVM\")\n",
        "      Model.store_metrics(list(Model.y_test), list(Model.MNB_model.predict(Model.vec.transform(Model.x_test))), \"MNB\")\n",
        "      max, mnb, svm_ = 0, 1, 1\n",
        "      for i in range(81, 101):\n",
        "        Model.mnb = i\n",
        "        for j in range(1, 101):\n",
        "          Model.svm_ = j\n",
        "          ypred = [Model.predict(ss)['res'].lower() for ss in list(Model.x_test)]\n",
        "          temp = Model.store_metrics(list(Model.y_test), ypred, \"AVG\", i == j)\n",
        "          if temp > max:\n",
        "            max = temp\n",
        "            mnb = i\n",
        "            SVM_model = j\n",
        "            print(f'Optimized mnb: {i} and svm: {j} till now.')\n",
        "            if j%10 == 0:\n",
        "              print(f'i={i}, j={j}')\n",
        "      Model.mnb, Model.svm_ = mnb, svm_\n",
        "  # def store_metrics(y_true, y_pred, what, save = False, mnb=1, svm=1)\n",
        "  # def predict(statement, mnb=1, svm=1, details=False)\n",
        "  @staticmethod\n",
        "  def necessary_lib_files():\n",
        "    lib_files = ['from sklearn.model_selection import train_test_split',\n",
        "           'from sklearn.feature_extraction.text import CountVectorizer',\n",
        "           'from sklearn.naive_bayes import MultinomialNB',\n",
        "           'from sklearn import svm',\n",
        "           'import pickle',\n",
        "           'import pandas as pd',\n",
        "           'CSV/opposite.csv',\n",
        "           'CSV/unwanted.csv',\n",
        "           'Folder: Model',\n",
        "           ]\n",
        "    print(f'Necessary items:\\n{lib_files}')\n",
        "  \n",
        "  @staticmethod\n",
        "  def load_model_vectorizer(MNB_path, SVM_path, vec_path):\n",
        "    Model.vec = pickle.load(open(vec_path, 'rb'))\n",
        "    Model.MNB_model = pickle.load(open(MNB_path, 'rb'))\n",
        "    Model.SVM_model = pickle.load(open(SVM_path, 'rb'))\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBP2834rfAzE"
      },
      "source": [
        "# For re-generating model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSMJDQVfH70",
        "outputId": "8bf49cbf-ea6e-46cf-e452-fcafbf780753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering the DataFrame ...\n",
            "Performing Train/Test split ...\n",
            "Vectorizing ...\n",
            "Generating SVM Model...\n",
            "Generating MNB Model...\n",
            "Calculationg model scores ...\n",
            "Optimized mnb: 81 and svm: 1 till now.\n",
            "Optimized mnb: 81 and svm: 2 till now.\n",
            "Optimized mnb: 81 and svm: 3 till now.\n",
            "Optimized mnb: 81 and svm: 5 till now.\n",
            "Optimized mnb: 81 and svm: 6 till now.\n",
            "Optimized mnb: 81 and svm: 7 till now.\n",
            "Optimized mnb: 81 and svm: 8 till now.\n",
            "Optimized mnb: 81 and svm: 9 till now.\n",
            "Optimized mnb: 81 and svm: 10 till now.\n",
            "i=81, j=10\n",
            "Optimized mnb: 81 and svm: 11 till now.\n",
            "Optimized mnb: 81 and svm: 12 till now.\n",
            "Optimized mnb: 81 and svm: 13 till now.\n",
            "Optimized mnb: 81 and svm: 14 till now.\n",
            "Optimized mnb: 81 and svm: 15 till now.\n",
            "Optimized mnb: 81 and svm: 16 till now.\n",
            "Optimized mnb: 81 and svm: 17 till now.\n",
            "Optimized mnb: 81 and svm: 18 till now.\n",
            "Optimized mnb: 81 and svm: 19 till now.\n",
            "Optimized mnb: 81 and svm: 20 till now.\n",
            "i=81, j=20\n",
            "Optimized mnb: 81 and svm: 21 till now.\n",
            "Optimized mnb: 81 and svm: 22 till now.\n",
            "Optimized mnb: 81 and svm: 23 till now.\n",
            "Optimized mnb: 81 and svm: 24 till now.\n",
            "Optimized mnb: 81 and svm: 25 till now.\n",
            "Optimized mnb: 81 and svm: 26 till now.\n",
            "Optimized mnb: 81 and svm: 27 till now.\n",
            "Optimized mnb: 81 and svm: 28 till now.\n",
            "Optimized mnb: 81 and svm: 29 till now.\n",
            "Optimized mnb: 81 and svm: 30 till now.\n",
            "i=81, j=30\n",
            "Optimized mnb: 81 and svm: 31 till now.\n",
            "Optimized mnb: 81 and svm: 33 till now.\n",
            "Optimized mnb: 81 and svm: 34 till now.\n",
            "Optimized mnb: 81 and svm: 35 till now.\n",
            "Optimized mnb: 81 and svm: 36 till now.\n",
            "Optimized mnb: 81 and svm: 37 till now.\n",
            "Optimized mnb: 81 and svm: 38 till now.\n",
            "Optimized mnb: 81 and svm: 39 till now.\n",
            "Optimized mnb: 81 and svm: 40 till now.\n",
            "i=81, j=40\n",
            "Optimized mnb: 81 and svm: 41 till now.\n",
            "Optimized mnb: 81 and svm: 42 till now.\n",
            "Optimized mnb: 81 and svm: 43 till now.\n",
            "Optimized mnb: 81 and svm: 44 till now.\n",
            "Optimized mnb: 81 and svm: 45 till now.\n",
            "Optimized mnb: 81 and svm: 46 till now.\n",
            "Optimized mnb: 81 and svm: 47 till now.\n",
            "Optimized mnb: 81 and svm: 48 till now.\n",
            "Optimized mnb: 81 and svm: 49 till now.\n",
            "Optimized mnb: 81 and svm: 50 till now.\n",
            "i=81, j=50\n",
            "Optimized mnb: 81 and svm: 51 till now.\n",
            "Optimized mnb: 81 and svm: 52 till now.\n",
            "Optimized mnb: 81 and svm: 53 till now.\n",
            "Optimized mnb: 81 and svm: 54 till now.\n",
            "Optimized mnb: 81 and svm: 55 till now.\n",
            "Optimized mnb: 81 and svm: 56 till now.\n",
            "Optimized mnb: 81 and svm: 57 till now.\n",
            "Optimized mnb: 81 and svm: 59 till now.\n",
            "Optimized mnb: 81 and svm: 60 till now.\n",
            "i=81, j=60\n",
            "Optimized mnb: 81 and svm: 61 till now.\n",
            "Optimized mnb: 81 and svm: 62 till now.\n",
            "Optimized mnb: 81 and svm: 63 till now.\n",
            "Optimized mnb: 81 and svm: 64 till now.\n",
            "Optimized mnb: 81 and svm: 65 till now.\n",
            "Optimized mnb: 81 and svm: 66 till now.\n",
            "Optimized mnb: 81 and svm: 67 till now.\n",
            "Optimized mnb: 81 and svm: 68 till now.\n",
            "Optimized mnb: 81 and svm: 69 till now.\n",
            "Optimized mnb: 81 and svm: 71 till now.\n",
            "Optimized mnb: 81 and svm: 72 till now.\n",
            "Optimized mnb: 81 and svm: 73 till now.\n",
            "Optimized mnb: 81 and svm: 74 till now.\n",
            "Optimized mnb: 81 and svm: 75 till now.\n",
            "Optimized mnb: 81 and svm: 76 till now.\n",
            "Optimized mnb: 81 and svm: 77 till now.\n",
            "Optimized mnb: 81 and svm: 78 till now.\n",
            "Optimized mnb: 81 and svm: 79 till now.\n",
            "SAscore5.csv written !\n",
            "Optimized mnb: 81 and svm: 81 till now.\n",
            "Optimized mnb: 81 and svm: 82 till now.\n",
            "Optimized mnb: 81 and svm: 85 till now.\n",
            "Optimized mnb: 81 and svm: 86 till now.\n",
            "Optimized mnb: 81 and svm: 87 till now.\n",
            "Optimized mnb: 81 and svm: 88 till now.\n",
            "Optimized mnb: 81 and svm: 91 till now.\n",
            "Optimized mnb: 81 and svm: 93 till now.\n",
            "Optimized mnb: 81 and svm: 94 till now.\n",
            "Optimized mnb: 81 and svm: 96 till now.\n",
            "Optimized mnb: 81 and svm: 97 till now.\n",
            "Optimized mnb: 81 and svm: 98 till now.\n",
            "Optimized mnb: 81 and svm: 100 till now.\n",
            "i=81, j=100\n",
            "SAscore5.csv written !\n",
            "SAscore5.csv written !\n"
          ]
        }
      ],
      "source": [
        "Model.generateModel(pd.read_csv('CSV/statementsWithoutLove.csv'), 'Statements', 'Sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq2PJHqQVdEq"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(Model.mertircs).to_csv('SAscore5.csv', index=False)\n",
        "print('SAscore5.csv written !' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvMdN9zRZo5R"
      },
      "source": [
        "# Feeding saved MNB, SVM and vectorizer to Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYtBR8zaZoSd"
      },
      "outputs": [],
      "source": [
        "Model.load_model_vectorizer('Model/modelMNB.sav', 'Model/modelSVM.sav', 'Model/vectorizer.sav')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X7dtyeQ7rcR"
      },
      "source": [
        "# Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks0-ow2V7wIW",
        "outputId": "68a3af7a-6ede-4159-cece-d141cf9be9d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SENTIMENT: JOY   \tCONFIDENCE: 0.6669780200979126\n",
            "SENTIMENT: JOY   \tCONFIDENCE: 0.5128894353899277\n",
            "SENTIMENT: ANGER   \tCONFIDENCE: 0.7716755654856913\n",
            "SENTIMENT: JOY   \tCONFIDENCE: 0.8993673462378845\n",
            "SENTIMENT: SADNESS   \tCONFIDENCE: 0.8106465860367423\n"
          ]
        }
      ],
      "source": [
        "inputs = ['Love this!', \n",
        "          'I absolutely hate this!', \n",
        "          'I am so much angry, I cant even tell you.',\n",
        "          'I am not angry at all.', \n",
        "          'I have not been happy since ages.',\n",
        "          ]\n",
        "for i in inputs:\n",
        "  print(f\"SENTIMENT: {Model.predict(i)['res']}   \\tCONFIDENCE: {Model.predict(i)['prob']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
